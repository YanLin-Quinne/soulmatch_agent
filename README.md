---
title: SoulMatch Agent
emoji: ğŸ’•
colorFrom: blue
colorTo: green
sdk: docker
pinned: false
license: mit
---

# SoulMatch Agent v2.0

**Multi-Agent Relationship Prediction System**

A multi-agent orchestration system with **12 collaborative agents**, **Bayesian feature inference**, **conformal uncertainty quantification**, and **three-layer cognitive memory**. This is not a single-LLM chatbot â€” agents run in parallel, share context through a blackboard, and adaptively steer conversations based on statistical uncertainty.

![Python 3.11+](https://img.shields.io/badge/Python-3.11%2B-blue)
![License MIT](https://img.shields.io/badge/License-MIT-green)
![HuggingFace Spaces](https://img.shields.io/badge/%F0%9F%A4%97-HuggingFace%20Spaces-yellow)

**Live Demo**: [huggingface.co/spaces/Quinnnnnne/SoulMatch-Agent](https://huggingface.co/spaces/Quinnnnnne/SoulMatch-Agent)

---

## Architecture Overview

![Architecture Overview](docs/architecture_overview.jpg)

![SoulMatch Framework â€” Multi-Agent + Bayesian + Conformal Prediction](docs/soulmatch_framework.png)

Each user message triggers a 5-phase DAG pipeline â€” not a simple sequential chain, but a directed acyclic graph with data dependencies:

```
User Message
     â”‚
     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Phase 1 â€” PARALLEL (asyncio.gather)            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Emotion  â”‚ â”‚ Scam         â”‚ â”‚ Memory      â”‚  â”‚
â”‚  â”‚ Agent    â”‚ â”‚ Detection    â”‚ â”‚ Retrieval   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚              â”‚                â”‚
        â–¼              â–¼                â–¼
   SharedAgentContext (blackboard writes)
        â”‚
        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Phase 2 â€” SEQUENTIAL                           â”‚
â”‚  Feature Prediction â†’ Bayesian Update           â”‚
â”‚  â†’ Conformal Calibration (APS)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Phase 3 â€” SEQUENTIAL                           â”‚
â”‚  Question Strategy (reads low-confidence list)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Phase 4 â€” SEQUENTIAL                           â”‚
â”‚  Bot Response (persona + probes + context)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Phase 5 â€” SEQUENTIAL                           â”‚
â”‚  Memory Store + Relationship Prediction (5-turn)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 8 Architectural Highlights

### 1. Pipeline DAG Execution

The orchestrator (`src/agents/orchestrator.py`) coordinates 12 agents through a 5-phase DAG. Phase 1 runs three independent agents concurrently via `asyncio.gather`; subsequent phases consume upstream results through the shared context. This is a genuine parallel + sequential DAG â€” not a flat chain.

### 2. SharedAgentContext (Blackboard Pattern)

A single mutable dataclass (`src/agents/agent_context.py`) with 80+ fields flows through every agent each turn. Fields span emotion state, 22-dim feature predictions, memory summaries, scam risk scores, tool results, discussion synthesis, and relationship snapshots. Agents read upstream results and write their own outputs â€” zero direct inter-agent coupling.

```python
@dataclass
class AgentContext:
    # Emotion (written by EmotionAgent)
    current_emotion: Optional[str] = None
    emotion_confidence: float = 0.0
    # Features (written by FeaturePredictionAgent)
    predicted_features: dict[str, Any] = field(default_factory=dict)
    feature_confidences: dict[str, float] = field(default_factory=dict)
    low_confidence_features: list[str] = field(default_factory=list)
    # ... 80+ fields total
```

### 3. Multi-LLM Router with Fallback Chains

The router (`src/agents/llm_router.py`) manages 5 LLM providers with per-role routing and automatic failover:

| Role | Primary Model | Fallback Chain |
|------|--------------|----------------|
| PERSONA (quality) | Claude Opus 4.6 | â†’ GPT-5.2 â†’ Gemini 3.1 Pro |
| FEATURE (reasoning) | Claude Opus 4.6 | â†’ DeepSeek Reasoner â†’ GPT-5.2 |
| EMOTION (speed) | Qwen 3.5 Plus | â†’ GPT-5.2 â†’ Claude Haiku |
| SCAM (cost) | Qwen 3.5 Plus | â†’ DeepSeek â†’ Gemini Flash |

Every call tracks token usage and cost. If the primary provider fails, the router automatically tries the next model in the chain.

### 4. Bayesian Feature Updater + Convergence Detection

The Bayesian updater (`src/agents/bayesian_updater.py`) maintains posterior distributions over 22 personality dimensions. Each turn:

1. LLM extracts a new observation with confidence
2. Confidence â†’ precision: `precision = confidenceÂ² Ã— 10`
3. Posterior mean = weighted average by precision (prior + observation)
4. Posterior confidence = `1 - 1/âˆšposterior_precision`

When confidence crosses **0.80**, the feature is "locked" â€” no more probing needed. Low-confidence features are passed to the Question Strategy Agent for targeted information gathering.

### 5. Conformal Prediction (APS) with Coverage Guarantees

The conformal calibrator (`src/agents/conformal_calibrator.py`) converts uncalibrated LLM confidence into statistically valid prediction sets using Adaptive Prediction Sets (APS):

- **Coverage guarantee**: P(Y_true âˆˆ C(X)) â‰¥ 1 - Î± (default Î± = 0.10, i.e., 90% coverage)
- **22 dimensions**: categorical (sex, orientation, diet, religion, ...) and continuous (age, openness, conscientiousness, ...)
- **Per-turn calibration** with adaptive Î± adjustment for sequential non-exchangeability
- **Frontend visualization**: prediction sets with calibrated vs. raw LLM confidence

References: Angelopoulos & Bates (2021), Kumar et al. (2023), Sheng et al. (2025, arXiv:2509.18658).

### 6. Tool Calling: Dual-Mode (Native + ReAct)

Agents can invoke tools through two mechanisms:

- **Native function calling**: structured tool use with parameter schemas (time, weather, web search, dating advice, compatibility analysis)
- **ReAct fallback** (`src/agents/reasoning.py`): Thought â†’ Action â†’ Observation loops when native mode is unavailable

The system also supports **Chain-of-Thought** reasoning â€” the LLM decomposes complex decisions into explicit steps with `<reasoning>` / `<conclusion>` tags before producing a final answer with calibrated confidence.

### 7. Three-Layer Cognitive Memory Architecture

The memory system (`src/memory/three_layer_memory.py`) implements a biologically-inspired three-layer architecture:

| Layer | Trigger | Content | Retention |
|-------|---------|---------|-----------|
| Working Memory | Every turn | Raw dialogue | 20-turn sliding window |
| Episodic Memory | Every 10 turns | LLM-compressed summary + key events + emotion trend | Permanent |
| Semantic Memory | Every 50 turns | LLM reflection â†’ feature updates + relationship insights | Permanent |

**Anti-hallucination mechanisms**:
- Strict grounding: all summaries must cite turn numbers
- Consistency check: independent LLM verification every 20 turns
- Conflict resolution: when new memory contradicts old, the system resolves via evidence weighting

The frontend displays episodic and semantic memory content in real-time.

### 8. Confidence-Driven Adaptive Dialogue Strategy

This is the **soul** of the system â€” conversation is steered by statistical uncertainty, not scripted flows.

```
Bayesian Updater â†’ identifies low-confidence features
        â”‚
        â–¼
Question Strategy Agent â†’ generates probes
  (direct_question / hint / self_disclosure / topic_shift)
        â”‚
        â–¼
Persona Agent â†’ weaves probes into natural conversation
        â”‚
        â–¼
User responds â†’ Feature Prediction â†’ Bayesian Update
        â”‚
        â–¼
Confidence increases â†’ fewer probes â†’ more natural chat
```

The `QuestionStrategyAgent` receives the list of low-confidence features and generates 1-3 conversation strategies using different approach types. As confidence converges toward 0.80, probing decreases and conversation becomes free-flowing. This creates an adaptive feedback loop: **uncertainty drives questions â†’ answers reduce uncertainty â†’ conversation evolves**.

---

## Tech Stack

| Component | Technology |
|-----------|-----------|
| Backend | Python 3.11, FastAPI, WebSocket, asyncio |
| Frontend | React 18, TypeScript, Vite |
| LLM Providers | Anthropic (Claude), OpenAI (GPT), Google (Gemini), Alibaba Cloud (Qwen), DeepSeek |
| Vector Store | ChromaDB |
| Memory | Three-layer cognitive memory (custom) |
| Deployment | Docker, HuggingFace Spaces |

---

## Project Structure

```
src/
â”œâ”€â”€ agents/                          # 12 agent implementations
â”‚   â”œâ”€â”€ orchestrator.py              # DAG pipeline coordinator
â”‚   â”œâ”€â”€ agent_context.py             # SharedAgentContext (blackboard)
â”‚   â”œâ”€â”€ llm_router.py                # Multi-LLM router with fallback
â”‚   â”œâ”€â”€ bayesian_updater.py          # Bayesian feature updater
â”‚   â”œâ”€â”€ conformal_calibrator.py      # Conformal prediction (APS)
â”‚   â”œâ”€â”€ persona_agent.py             # Bot personality + response gen
â”‚   â”œâ”€â”€ emotion_agent.py             # Emotion classification
â”‚   â”œâ”€â”€ feature_prediction_agent.py  # 22-dim feature extraction
â”‚   â”œâ”€â”€ question_strategy_agent.py   # Confidence-driven probing
â”‚   â”œâ”€â”€ scam_detection_agent.py      # Scam pattern detection
â”‚   â”œâ”€â”€ relationship_prediction_agent.py  # Social agents voting
â”‚   â”œâ”€â”€ reasoning.py                 # CoT + ReAct reasoning
â”‚   â””â”€â”€ tools/                       # Tool calling infrastructure
â”œâ”€â”€ memory/                          # Three-layer memory system
â”‚   â””â”€â”€ three_layer_memory.py
â”œâ”€â”€ api/                             # FastAPI + WebSocket handlers
â”œâ”€â”€ data/                            # Feature extraction + persona builder
â”œâ”€â”€ matching/                        # Compatibility scoring engine
â””â”€â”€ training/                        # Calibration + RL pipelines
frontend/
â”œâ”€â”€ src/App.tsx                      # Main React app (real-time viz)
â””â”€â”€ src/components/                  # RelationshipTab, charts, memory
```

---

## Quick Start

```bash
git clone https://github.com/YanLin-Quinne/soulmatch_agent.git
cd soulmatch_agent
cp .env.example .env   # Add your API keys
pip install -r requirements.txt
cd frontend && npm install && npm run build && cd ..
python -m src.api.main
```

Open `http://localhost:7860` in your browser.

---

## License

MIT
