# LLM API Keys (2026-02-22 Latest Models)
# OpenAI GPT-5.2
OPENAI_API_KEY=sk-proj-your-openai-key-here

# Google Gemini 3.1 Pro Preview / 2.5 Flash
GEMINI_API_KEY=your-gemini-key-here

# Anthropic Claude Opus 4.6
ANTHROPIC_API_KEY=sk-ant-api03-your-anthropic-key-here

# Alibaba Qwen 3.5 Plus
QWEN_API_KEY=sk-your-qwen-key-here

# DeepSeek V3.2 (DeepSeek-Reasoner)
DEEPSEEK_API_KEY=sk-your-deepseek-key-here

# Database
CHROMA_DB_PATH=./chroma_db

# Training Configuration
MODEL_NAME=Qwen/Qwen2.5-0.5B
DEVICE=mps  # Options: cpu, cuda, mps
BATCH_SIZE=4
LEARNING_RATE=2e-5
MAX_EPOCHS=3

# API Configuration
API_HOST=0.0.0.0
API_PORT=8000
CORS_ORIGINS=http://localhost:3000,http://localhost:5173

# Local LLM (vLLM / Ollama / llama.cpp server â€” OpenAI-compatible endpoint)
LOCAL_LLM_BASE_URL=  # e.g. "http://localhost:8080/v1"
LOCAL_LLM_MODEL=     # model name the server expects
LOCAL_LLM_API_KEY=not-needed

# HuggingFace (transformers pipeline, no external server needed)
HF_MODEL_NAME=       # e.g. "Qwen/Qwen3-0.6B"
HF_DEVICE=           # "cpu", "cuda", "mps"; empty = auto-detect

# Kaggle
KAGGLE_USERNAME=your_kaggle_username
KAGGLE_KEY=your_kaggle_key

# Logging
LOG_LEVEL=INFO
